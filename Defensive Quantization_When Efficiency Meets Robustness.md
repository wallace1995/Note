# DEFENSIVE QUANTIZATION: WHEN EFFICIENCY MEETS ROBUSTNESS

# 摘要

如今神经网络量化法已经成为了一种在硬件平台上高效实施深度学习模型的工业标准，传统的神经网络量化方法容易遭到对抗性攻击，本论文旨在提醒人们关注神经网络量化模型的安全性，并设计了一种方法同同时优化深度学习网络的高效性和鲁棒性。我们首先实施了一个经验上的研究来展示 vanilla 量化方法容易遭到对抗性攻击，我们观察到误差放大效应**（error amplification effect）**导致的低鲁棒性，其中量化操作进一步扩大了由放大的噪声引起的距离**（amplified noise）**。然后我们提出了一种新颖的防御量化方法 **（Defensive Quantization method，DQ）**，通过控制量化期间网络的 **Lipschitz** 常量，使得对抗噪声的量级在推理过程中不被放大。大量的实验表明我们的新型量化方法可以让神经网络抵御对抗性样本，并且在保持 vanilla 量化法效率的同时实现更优秀的鲁棒性。同时，**DQ** 在没有对抗性攻击的情况下提高量化方法的准确率。

