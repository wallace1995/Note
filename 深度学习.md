# 深度学习

# 全书架构

![deeplearning](C:\Users\w50005335\Pictures\deeplearning.PNG)

# 深度学习简介

**表征学习（Representation Learning）**是一种特征学习方式，使用机器学习来发掘能表征自身的**特性（Feature）**，典型例子是**自编码器（Autoencoder）**，自编码器由一个**编码器（encoder）**函数和一个**解码器（decoder）**函数组合而成。编码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换到原来的形式。我们期望当输入数据经过编码器和解码器之后尽可能多地保留信息，并且能挖掘出更多优秀的特性，这也是自编码器的训练目标。

当设计表征学习算法时，我们的目标通常是分离出能解释观察数据的**变差因素（factors of variation）**。这些因素通常是不能被直接观察到的量。相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量。从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难。

**深度学习（deep learning）**通过其他较简单的表征来表达复杂表示，解决了表征学习中的核心问题。深度学习将所需的复杂映射分解为一系列嵌套的简单映射（每个由模型的不同层描述）来解决这一难题。输入展示在**可见层（visible layer）**，这样命名的原因是因为它包含我们能观察到的变量。然后是一系列从图像中提取越来越多抽象特征的**隐藏层（hidden layer）**。因为它们的值不在数据中给出，所以将这些层称为‘‘隐藏”。模型必须确定哪些概念有利于解释观察数据中的关系。

深度学习模型的典型例子是**前馈深度网络**或**多层感知机（multilayer perceptron, MLP）**。多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都
为输入提供了新的表征。深度学习的另一个最大的成就是其在**强化学习（reinforcement learning）**领域的扩展。在强化学习中，一个自主的智能体必须在没有人类操作者指导的情况下，通过试错来学习执行任务

# 数学基础

## 线性代数

### 基本概念

- **标量（scalar）**：一个标量就是一个单独的数
- **向量（vector）**：一个向量是一列数，如果每个元素都属于$\mathbb{R}$，并且该向量有$n$ 个元素，记为 $\mathbb{R}_n$
- **矩阵（matrix）**：矩阵是一个二维数组，如果一个实数矩阵$A$高度为$m$，宽度为$n$，那么我们说 $A \in \mathbb{R}^{m \times n}$
- **张量（tensor）**：坐标超过两维的数组。张量A 中坐标为$(i, j, k)$的元素记作 $A_{i,j,k}$

### 矩阵乘法

- **矩阵乘积**：记作 $C = AB$，计算方法为 $C_{i, j}=\sum_{k} A_{i, k} B_{k, j}$，不服从交换律
- **矩阵点积**：记作 $C=A \odot B$，计算方法为两个矩阵对应元素相乘（$C=A^{\top}B$），服从交换律，分配律和结合律

### 矩阵求逆

矩阵$A$的**矩阵逆（matrix inversion）**记作$A^{-1}$，其定义的矩阵满足如下条件:
$$
\boldsymbol{A}^{-1} \boldsymbol{A}=\boldsymbol{I}_{n}
$$

### 线性组合 

$$
w = \sum_{i} c_{i} v^{(i)}
$$

若一组向量中任意一个向量都不能表示成其他向量的**线性组合（linear combination）**，那么这组向量称为**线性无关（linearly independent）**，否则称为**线性相关（linear dependence）**

### 范数

在机器学习中，我们经常使用被称为**范数（norm）**的函数衡量向量大小。形式上，$L^p$ 范数定义如下
$$
\|x\|_{p}=\left(\sum_{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}
$$
范数是将向量映射到非负值的函数。直观上来说，向量 $x$ 的范数衡量从原点到点 $x$ 的距离。

当$p = 2$时，$L^2$ 范数被称为**欧几里得范数（Euclidean norm）**。它表示从原点出发到向量 $x$ 确定的点的欧几里得距离。L2 范数在机器学习中出现地十分频繁，经常简化表示为 $∥x∥$。

平方 $L^2$ 范数也经常用来衡量向量的大小，可以简单地通过点积 $x^⊤x$ 计算。但是在很多情况下，平方L2 范数也可能不受欢迎，因为它在原点附近增长得十分缓慢。在某些机器学习应用中，区分恰好是零的元素和非零但值很小的元素是很重要的。在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的数学形式的函数：$L^1$ 范数。$L^1$ 范数可以简化如下：
$$
\|x\|_{1}=\sum_{i}\left|x_{i}\right|
$$
另外一个经常在机器学习中出现的范数是 $L^\infty$ 范数，也被称为**最大范数（maxnorm）**。这个范数表示向量中具有最大幅值的元素的绝对值：
$$
\|x\|_{\infty}=\max _{i}\left|x_{i}\right|
$$

最大范数约束：最大值不超过某个数
$$
\|x\|_{\infty}=c
$$
衡量矩阵的大小时，最常见的做法是使用 **Frobenius 范数（Frobenius norm）**，
$$
\|A\|_{F}=\sqrt{\sum_{i, j} A_{i, j}^{2}}
$$

### 特殊矩阵

- 正交矩阵（orthogonal matrix）

  指行向量和列向量是分别标准正交的方阵，$A^{\top} A=A A^{\top}=I$，这意味着 $A^{-1}=A^{\top}$

- 对角矩阵（diagonal matrix）

  只在主对角线上含有非零元素，其他位置都是零， 表示一个对角元素由向量 $v$ 中元素给定的对角方阵记作$diag(v)$

  计算乘法 $diag(v)x$，我们只需要将 $x$ 中的每个元素 $x_i$ 放大 $v_i$ 倍。换言之，$diag(v)x = v ⊙ x$。

  对角方阵的逆矩阵存在，当且仅当对角元素都是非零值，$diag(v)^{-1} = diag([1/v_1,... , 1/v_n]^⊤)$。

- 对称矩阵（symmetric matrix）

  矩阵是转置和自己相等的矩阵，$A=A^{\top}$

- 单位向量（unit vector）

  具有**单位范数（unit norm）**的向量：$∥x∥ = 1$

### 特征分解

**特征分解（eigendecomposition）**是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值，非方阵的矩阵没有特征分解。

方阵 $A$ 的**特征向量（eigenvector）**是指与 $A$ 相乘后相当于对该向量进行缩放的非零向量 $v$，标量 $\lambda$ 被称为这个特征向量对应的**特征值（eigenvalue）**
$$
A v=\lambda v
$$

假设矩阵$A$ 有$n$ 个线性无关的特征向量 $\{v_1,....v_n\}$，对应着特征值 $\{\lambda_1,....\lambda_n\}$。我们将特征向量连接成一个矩阵,使得每一列是一个特征向量： $V = \{v_1,....v_n\}$。类似地，我们也可以将特征值连接成一个向量$\lambda = \{\lambda_1,....\lambda_n\}$。
因此$A$ 的特征分解可以记作：
$$
A=V \operatorname{diag}(\lambda) V^{-1}
$$
每个实对称矩阵都可以分解成实特征向量和实特征值：
$$
A=Q \Lambda Q^{\top}
$$
其中$Q$ 是$A$ 的特征向量组成的正交矩阵， $\Lambda$ 是对角矩阵。特征值$\Lambda_{i,i}$ 对应的特征向量是矩阵$Q$ 的第$i$ 列，记作$Q_{:,i}$。因为$Q$ 是正交矩阵，我们可以将$A$ 看作沿方向 $v_i$ 延展$\lambda_i$ 倍的空间。如图所示：

![矩阵分解](C:\Users\w50005335\Pictures\矩阵分解.PNG)

所有特征值都是正数的矩阵被称为**正定（positive definite）**；所有特征值都是非负数的矩阵被称为**半正定（positive semidefinite）**。同样地，所有特征值都是负数的矩阵被称为**负定（negative definite）**；所有特征值都是非正数的矩阵被称为**半负定（negative semidefinite）**。半正定矩阵受到关注是因为它们保证 $\forall x, x^{\top} A x \geq 0$。此外，正定矩阵还保证 $x^{\top} A x=0 \Rightarrow x=0$。

### 奇异值分解

将矩阵分解为**奇异向量（singular vector）**和奇异值**（singular value）**的矩阵分解方法称为**奇异值分解（singular value decomposition, SVD）**，每个实数矩阵都有一个奇异值分解，但不一定都有特征分解。

假设 $A$ 是一个 $m \times n$ 的矩阵，那么 $U$ 是一个 $m \times m$ 的矩阵，D 是一个 $m \times n$ 的矩阵，V 是一个 $n \times n$ 矩阵。矩阵$U$ 和 $V$ 都定义为正交矩阵，而矩阵 $D$ 定义为对角矩阵。则 SVD 分解为：
$$
A=U D V^{\top}
$$
对角矩阵$D$ 对角线上的元素被称为矩阵$A$ 的**奇异值（singular value）**。矩阵$U$ 的列向量被称为**左奇异向量（left singular vector）**，矩阵$V$ 的列向量被称**右奇异向量（right singular vector）**。$A$ 的左奇异向量是$AA^⊤$ 的特征向量。$A$ 的右奇异向量是 $A^⊤A$ 的特征向量。$A$ 的非零奇异值是$A^⊤A$ 特征值的平方根，同时也是$AA^⊤$ 特征值的平方根。

### 迹运算

迹运算返回的是矩阵对角元素的和：
$$
\operatorname{Tr}(\boldsymbol{A})=\sum_{i} \boldsymbol{A}_{i, i}
$$

### 行列式

行列式，记作$det(A)$，是一个将方阵$A$ 映射到实数的函数。行列式等于矩阵特征值的乘积。



## 概率论

### 基本概念

**随机变量（random variable）**是可以随机地取不同值的变量。

**概率分布（probability distribution）**用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。我们描述概率分布的方式取决于随机变量是离散的还是连续的。

**离散型变量**的概率分布可以用**概率质量函数（probability mass function, PMF）**来描述。概率质量函数将随机变量能够取得的每个状态映射到随机变量取得该状态的概率。$x = x$ 的概率用$P(x)$ 来表示，记为 $\mathrm{x} \sim P(\mathrm{x})$。

多个变量的概率分布被称为**联合概率分布（joint probability distribution）**。$P(x = x, y = y)$ 表示$x = x$ 和$y = y$ 同时发生的概率。我们也可以简写为$P(x,y)$。

例如，一个离散型随机变量$x$ 有$k$ 个不同的状态。我们可以假设$x$ 是**均匀分布（uniform distribution）**的，将它
的PMF设为：
$$
P\left(\mathrm{x}=x_{i}\right)=\frac{1}{k}
$$
对于所有的$i$ 都成立。

**连续型随机变量**的概率分布可以用**概率密度函数（probability density function, PDF）**描述，概率密度函数$p(x)$ 并没有直接对特定的状态给出概率，相对的，它给出了落在面积为 $\delta x$ 的无限小的区域内的概率为 $p(x)\delta x$。$x$ 落在集合$S$ 中的概率可以通过$p(x)$ 对这个集合求积分来得到。在单变量的例子中，$x$ 落在区间$[a,b]$ 的概率是 $\int_{[a, b]} p(x) d x$。我们通常用 $\mathrm{x} \sim U(a, b)$表示$x$ 在$[a, b]$ 上是均匀分布的。

### 边缘概率

已知一组变量的联合概率分布，想要了解其中一个子集的概率分布。这种定义在子集上的概率分布被称为**边缘概率分布（marginal probability distribution）**。例如，假设有离散型随机变量$x$ 和$y$，并且我们知道$P(x, y)$。我们可以依据下面的**求和法则（sum rule）**来计算$P(x)$：
$$
\forall x \in \mathrm{x}, P(\mathrm{x}=x)=\sum_{y} P(\mathrm{x}=x, \mathrm{y}=y)
$$
对于连续型变量，我们需要用积分替代求和：
$$
p(x)=\int p(x, y) d y
$$

### 条件概率

#### 定义

某个事件，在给定其他事件发生时出现的概率叫做条件概率，将给定$x = x，y = y$ 发生的条件概率记为$P(y = y| x = x)$。这个条件概率可以通过下面的公式计算：
$$
P(\mathrm{y}=y | \mathrm{x}=x)=\frac{P(\mathrm{y}=y, \mathrm{x}=x)}{P(\mathrm{x}=x)}
$$

#### 链式法则

任何多维随机变量的联合概率分布，都可以分解成只有一个变量的条件概率相乘的形式：
$$
P\left(\mathrm{x}^{(1)}, \ldots, \mathrm{x}^{(n)}\right)=P\left(\mathrm{x}^{(1)}\right) \Pi_{i=2}^{n} P\left(\mathrm{x}^{(i)} | \mathrm{x}^{(1)}, \ldots, \mathrm{x}^{(i-1)}\right)
$$
例如：
$$
\begin{array} {c} {P(\mathrm{a}, \mathrm{b}, \mathrm{c}) =P(\mathrm{a} | \mathrm{b}, \mathrm{c}) P(\mathrm{b}, \mathrm{c})} \\ {P(\mathrm{b}, \mathrm{c}) =P(\mathrm{b} | \mathrm{c}) P(\mathrm{c})} \\ {P(\mathrm{a}, \mathrm{b}, \mathrm{c}) =P(\mathrm{a} | \mathrm{b}, \mathrm{c}) P(\mathrm{b} | \mathrm{c}) P(\mathrm{c})} \end{array}
$$

#### 独立性和条件独立性

当满足下列等式是，随机变量 $x$和$y$ **相互独立（independent）**，
$$
\forall x \in \mathrm{x}, y \in \mathrm{y}, p(\mathrm{x}=x, \mathrm{y}=y)=p(\mathrm{x}=x) p(\mathrm{y}=y)
$$
如果关于$x$ 和$y$ 的条件概率分布对于$z$ 的每一个值都可以写成乘积的形式，那么这两个随机变量$x$ 和$y$ 在给定随机变量$z$ 时是**条件独立的（conditionally independent）**：
$$
\forall x \in \mathrm{x}, y \in \mathrm{y}, z \in \mathrm{z}, p(\mathrm{x}=x, \mathrm{y}=y | \mathrm{z}=z)=p(\mathrm{x}=x | \mathrm{z}=z) p(\mathrm{y}=y | \mathrm{z}=z)
$$
$x \perp y$ 表示$x$ 和$y$ 相互独立，$x \perp y|z$ 表示$x$ 和$y$ 在给定$z$ 时条件独立。

### 期望、方差和协方差

函数$f(x)$ 关于某分布$P(x)$ 的**期望（expectation）**或者**期望值（expected value）**是指，当$x$ 由$P$产生，$f$ 作用于$x$ 时，$f(x)$ 的平均值。

对于离散型随机变量，这可以通过求和得到：
$$
\mathbb{E}_{\mathbf{x} \sim P}[f(x)]=\sum_{r} P(x) f(x)
$$
对于连续型随机变量可以通过求积分得到：
$$
\mathbb{E}_{\mathrm{x} \sim p}[f(x)]=\int p(x) f(x) d x
$$
期望是线性的，例如：
$$
\mathbb{E}_{\mathbf{x}}[\alpha f(x)+\beta g(x)]=\alpha \mathbb{E}_{\mathbf{x}}[f(x)]+\beta \mathbb{E}_{\mathbf{x}}[g(x)]
$$
**方差（variance）**衡量的是当我们对$x$ 依据它的概率分布进行采样时，随机变量$x$ 的函数值会呈现多大的差异：
$$
\operatorname{Var}(f(x))=\mathbb{E}\left[(f(x)-\mathbb{E}[f(x)])^{2}\right]
$$
方差的平方根被称为**标准差（standard deviation）**。

**协方差（covariance）**在某种意义上给出了两个变量线性相关性的强度以及这些变量的尺度：
$$
\operatorname{Cov}(f(x), g(y))=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])(g(y)-\mathbb{E}[g(y)])]
$$
协方差的绝对值如果很大则意味着变量值变化很大并且它们同时距离各自的均值很远。如果协方差是正的，那么两个变量都倾向于同时取得相对较大的值。如果协方差是负的，那么其中一个变量倾向于取得相对较大的值的同时，另一个变量倾向于取得相对较小的值。两个变量如果相互独立那么它们的协方差为零。

其他的衡量指标如**相关系数（correlation）**将每个变量的贡献归一化，为了只衡量变量的相关性而不受各个变量尺度大小的影响。

随机向量 $\boldsymbol{x} \in \mathbb{R}^{n}$ 的**协方差矩阵（covariance matrix）**是一个$n \times n$ 的矩阵，并且满足：
$$
\operatorname{Cov}(\mathrm{x})_{i, j}=\operatorname{Cov}\left(\mathrm{x}_{i}, \mathrm{x}_{j}\right)
$$
协方差矩阵的对角元是方差：
$$
\operatorname{Cov}\left(\mathrm{x}_{i}, \mathrm{x}_{i}\right)=\operatorname{Var}\left(\mathrm{x}_{i}\right)
$$

### 常用概率分布

#### Bernoulli 分布

Bernoulli 分布（Bernoulli distribution）是单个二值随机变量的分布。它由单个参数 $\Phi \in[0,1]$ 控制，$\Phi $ 给出了随机变量等于1 的概率。
$$
\begin{array}{c}{P(\mathrm{x}=1)=\phi} \\ {P(\mathrm{x}=0)=1-\phi} \\ {P(\mathrm{x}=x)=\phi^{x}(1-\phi)^{1-x}} \\ {\mathbb{E}_{\mathrm{x}}[\mathrm{x}]=\phi} \\ {\operatorname{Var}_{\mathrm{x}}(\mathrm{x})=\phi(1-\phi)}\end{array}
$$

#### 正态分布

实数上最常用的分布就是**正态分布（normal distribution）**，也称为**高斯分布（Gaussian distribution）**：
$$
\mathcal{N}\left(x ; \mu, \sigma^{2}\right)=\sqrt{\frac{1}{2 \pi \sigma^{2}}} \exp \left(-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right)
$$
$\mathcal{N}\left(x ; \mu, \sigma^{2}\right)$ 表示输入为$x$，参数为$\mu, \sigma^{2}$，正态分布$\mathcal{N}\left(x ; \mu, \sigma^{2}\right)$呈现经典的‘‘钟形曲线’’ 的形状，其中中心峰的 x 坐标
由 $\mu$ 给出，这也是分布的均值，峰的宽度受 $\sigma$ 控制，也是分布的标准差。**标准正态分布（standard normal distribution）** 的 $\mu=0, \sigma=1$。

一种更高效的参数化分布的方式是使用参数 $\beta \in(0, \infty)$ (或方差的倒数)，来控制分布的**精度（precision）**：
$$
\mathcal{N}\left(x ; \mu, \beta^{-1}\right)=\sqrt{\frac{\beta}{2 \pi}} \exp \left(-\frac{1}{2} \beta(x-\mu)^{2}\right)
$$
正态分布可以推广到$R^n$ 空间，这种情况下被称为**多维正态分布（multivariate normal distribution）**。它的参数是一个正定对称矩阵 $\mathbf{\Sigma}$：
$$
\mathcal{N}(x ; \boldsymbol{\mu}, \mathbf{\Sigma})=\sqrt{\frac{1}{(2 \pi)^{n} \operatorname{det}(\boldsymbol{\Sigma})}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\top} \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right)
$$
可以使用一个精度矩阵（precision matrix）$\beta$ 进行替代：
$$
\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{\mu}, \boldsymbol{\beta}^{-1}\right)=\sqrt{\frac{\operatorname{det}(\boldsymbol{\beta})}{(2 \pi)^{n}}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\top} \boldsymbol{\beta}(\boldsymbol{x}-\boldsymbol{\mu})\right)
$$

### 常用函数

#### logistic sigmoid 函数

$$
\sigma(x)=\frac{1}{1+\exp (-x)}
$$

sigmoid 函数的值域是 $(0,1)$，在变量取绝对值非常大的正值或负值时会出现饱和（saturate）现象，意味着函数会
变得很平，并且对输入的微小改变会变得不敏感，函数图像如下：

![sigmoid](C:\Users\w50005335\Pictures\sigmoid.PNG)

#### Relu 函数（整流线性激活函数）

$$
g(z)=\max (0, z)
$$

![Relu](C:\Users\w50005335\Pictures\Relu.PNG)

#### softplus 函数

$$
\zeta(x)=log (1+exp (x))
$$

softplus 函数是 Relu 函数的平滑（或‘‘软化’’）形式，softplus 函数图像如下：

![softplus](C:\Users\w50005335\Pictures\softplus.PNG)

下面一些性质非常有用：
$$
\begin{array}{c}{\sigma(x)=\frac{\exp (x)}{\exp (x)+\exp (0)}} \\ {\frac{d}{d x} \sigma(x)=\sigma(x)(1-\sigma(x))} \\ {1-\sigma(x)=\sigma(-x)} \\ {\log \sigma(x)=-\zeta(-x)} \\ {\frac{d}{d x} \zeta(x)=\sigma(x)}\\{\forall x \in(0,1), \sigma^{-1}(x)=\log \left(\frac{x}{1-x}\right)} \\ {\forall x>0, \zeta^{-1}(x)=\log (\exp (x)-1)}\\{\zeta(x)=\int_{-\infty}^{x} \sigma(y) d y} \\ {\zeta(x)-\zeta(-x)=x}\end{array}
$$

### 贝叶斯规则

$$
P(\mathrm{x} | \mathrm{y})=\frac{P(\mathrm{x}) P(\mathrm{y} | \mathrm{x})}{P(\mathrm{y})}
$$

### 信息论

信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事件发生能提供更多的信息，特别地，
• 非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件应该没有信息量。
• 较不可能发生的事件具有更高的信息量。
• 独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上的信息量的两倍。

为了满足上述三个性质，我们定义一个事件$x = x$ 的**自信息（self-information）**为：
$$
I(x)=-\log P(x)
$$
我们可以用**香农熵（Shannon entropy）**来对整个概率分布中的不确定性总量进行量化：
$$
H(\mathrm{x})=\mathbb{E}_{\mathrm{x} \sim P}[I(x)]=-\mathbb{E}_{\mathrm{x} \sim P}[\log P(x)]
$$
当x 是连续的，香农熵被称为**微分熵（differential entropy）**

如果我们对于同一个随机变量x 有两个单独的概率分布$P(x)$ 和$Q(x)$，我们可以使用**KL 散度（Kullback-Leibler (KL) divergence）**来衡量这两个分布的差异：
$$
D_{\mathrm{KL}}(P \| Q)=\mathbb{E}_{\mathrm{x} \sim P}\left[\log \frac{P(x)}{Q(x)}\right]=\mathbb{E}_{\mathrm{x} \sim P}[\log P(x)-\log Q(x)]
$$
因为KL 散度是非负的并且衡量的是两个分布之间的差异，它经常被用作分布之间的某种距离。然而，它并不是真的距离因为它不是对称的，$D_{\mathrm{KL}}(P \| Q) \neq D_{\mathrm{KL}}(Q \| P)$。

和KL 散度密切联系的量是**交叉熵（cross-entropy）**，$H(P,Q) = H(P) + D_{KL}(P||Q)$，
$$
H(P, Q)=-\mathbb{E}_{\mathbf{x} \sim P} \log Q(x)
$$

### 结构化概率模型

可以把概率分布分解成许多因子的乘积形式，而不是使用单一的函数来表示概率分布。可以用图来表示这种概率分布的分解，称为结**构化概率模型（structured probabilistic model）**或者**图模型（graphical model）**。

#### 有向图模型

**有向（directed）模型**使用带有有向边的图，它们用条件概率分布来表示分解，有向模型对于分布中的每一个随机变量$x_i$ 都包含着一个影响因子，这个组成$x_i$条件概率的影响因子被称为$x_i$ 的父节点，记为 ：$P a_{\mathcal{G}}\left(\mathrm{x}_{i}\right)$
$$
p(\mathrm{x})=\prod_{i} p\left(\mathrm{x}_{i} | \operatorname{Pa}_{\mathcal{G}}\left(\mathrm{x}_{i}\right)\right)
$$
例如，关于随机变量$a, b, c,d,e$ 的有向图模型，

![有向图模型](C:\Users\w50005335\Pictures\有向图模型.PNG)

这幅图对应的概率分布可以分解为：
$$
p(\mathrm{a}, \mathrm{b}, \mathrm{c}, \mathrm{d}, \mathrm{e})=p(\mathrm{a}) p(\mathrm{b} | \mathrm{a}) p(\mathrm{c} | \mathrm{a}, \mathrm{b}) p(\mathrm{d} | \mathrm{b}) p(\mathrm{e} | \mathrm{c})
$$

#### 无向图模型

**无向（undirected）模型**使用带有无向边的图，它们将分解表示成一组函数，$\mathcal{G}$ 中任何满足两两之间有边连接的顶点的集合被称为团。无向模型中的每个团$C^{(i)}$ 都伴随着一个因子 $ϕ^{(i)}(C^{(i)})$。随机变量的联合概率与所有这些因子的乘积成**比例（proportional）**，意味着因子的值越大则可能性越大。但是不能保证这种乘积的求和为1。所以需要除以一个归一化常数$Z$ 来得到归一化的概率分布，归一化常数$Z $被定义为$ϕ$ 函数乘积的所有状态的求和或积分。概率分布为：
$$
p(\mathbf{x})=\frac{1}{Z} \prod_{i} \phi^{(i)}\left(\mathcal{C}^{(i)}\right)
$$
例如，关于随机变量a; b; c; d 和e 的无向图模型，

![无向图模型](C:\Users\w50005335\Pictures\无向图模型.PNG)

这幅图对应的概率分布可以分解为：
$$
p(\mathrm{a}, \mathrm{b}, \mathrm{c}, \mathrm{d}, \mathrm{e})=\frac{1}{Z} \phi^{(1)}(\mathrm{a}, \mathrm{b}, \mathrm{c}) \phi^{(2)}(\mathrm{b}, \mathrm{d}) \phi^{(3)}(\mathrm{c}, \mathrm{e})
$$


## 数值计算

### 上溢和下溢

连续数学在数字计算机上的根本困难是，我们需要通过有限数量的位模式来表示无限多的实数。这意味着我们在计算机中表示实数时，几乎总会引入一些近似误差，例如舍入误差，舍入误差会导致一些问题，特别是当许多操作复合时，即使是理论上可行的算法，如果在设计时没有考虑最小化舍入误差的累积，在实践时也可能会导致算法失效。

一种极具毁灭性的舍入误差是下溢（underflow）。当接近零的数被四舍五入为零时发生下溢。另一个极具破坏力的数值错误形式是上溢（overflow）。当大量级的数被近似为$\infty$ 或$-\infty$ 时发生上溢。进一步的运算通常会导致这些无限值变为非数字。

必须对上溢和下溢进行数值稳定的一个例子是**softmax 函数**。定义为：
$$
\operatorname{softmax}(\boldsymbol{x})_{i}=\frac{\exp \left(x_{i}\right)}{\sum_{j=1}^{n} \exp \left(x_{j}\right)}
$$
若所有的 $x_j$ 都是极其小的负数，$exp(x_j)$ 就会下溢为0，softmax函数的分母就会变为0，导致零除错误。如果所有的 $x_j$ 都是极其大的正数，又会导致上溢，导致整个表达式无法计算。这两个问题可以通过计算 $softmax(z)$ 解决，其中$z=x-max_ix_i$，计算表明，softmax 解析上的函数值不会因为从输入向量减去或加上标量而改变。
$$
\frac{\exp ^{(x-a)}}{\sum_{i=1}^{k} \exp _{i}^{(x-a)}}=\frac{\exp ^{(x)} \exp ^{(-a)}}{\exp ^{(-a)} \sum_{i=1}^{k} \exp _{i}^{(x)}}=\frac{\exp ^{(x)}}{\sum_{i=1}^{k} \exp _{i}^{(x)}}
$$
减去了 $max_ix_i$，就可以保证最大参数为0，消除了上溢的可能性，同时分母至少有一个值为1的项，排除了下溢零除的可能性。

### 病态条件

条件数表征函数相对于输入的微小变化而变化的快慢程度。输入被轻微扰动而迅速改变的函数对于科学计算来说可能是有问题的，因为输入中的舍入误差可能导致输出的巨大变化。

### 基于梯度的优化方法

我们把要最小化或最大化的函数称为**目标函数（objective function）**或**准则（criterion）**。当我们对其进行最小化时，我们也把它称为**代价函数（cost function）**、**损失函数（loss function）**或**误差函数（error function）**。通常使用一个上标 $*$ 表示最小化或最大化函数的 $x$ 值（最优解），如 $x^* = arg min f(x)。$

对于函数$y = f(x)$，其中$x$ 和$y$ 是实数。这个函数的**导数（derivative）**记为$f′(x)$ 或 $\frac{d y}{d x}$。导数 $f′(x)$ 代表 $f(x)$ 在点 $x$ 处的斜率。换句话说，它表明如何缩放输入的小变化才能在输出获得相应的变化：$f(x+\epsilon) \approx f(x)+\epsilon f^{\prime}(x)$。因此导数对于最小化一个函数很有用，因为它告诉我们如何更改 $x$ 来略微地改善 $y$。因此我们可以将 $x$ 往导数的反方向移动一小步来减小$f(x)$。这种技术被称为**梯度下降（gradient descent）**。

当$f′(x) = 0$，导数无法提供往哪个方向移动的信息。$f′(x) = 0 $的点称为**临界点（critical point）**或**驻点（stationary point）**，一个**局部极小点（local minimum）**意味着这个点的$f(x)$ 小于所有邻近点，因此不可能通过移动无穷小的步长来减小$f(x)$。一个**局部极大点（local maximum）**意味着这个点的$f(x)$ 大于所有邻近点，因此不可能通过移动无穷小的步长来增大$f(x)$。有些临界点既不是极小点也不是极大点，这些点被称为**鞍点（saddle point）**。使f(x) 取得绝对的最小值（相对所有其他值）的点是**全局最小点（global minimum）**。

针对具有多维输入的函数，我们需要用到**偏导数（partial derivative）**的概念。偏导数$\frac{\partial}{\partial x_{\mathrm{i}}} f(\boldsymbol{x})$衡量点$x$ 处只有$x_i$ 增加时$f(x)$ 如何变化。**梯度（gradient）**是相对一个向量求导的导数：$f$ 的导数是包含所有偏导数的向量，记为$\nabla_{x} f(\boldsymbol{x})$。梯度的第$i$ 个元素是$f$ 关于$x_i$ 的偏导数。在多维情况下，临界点是梯度中所有元素都为零的点。

在 $u$（单位向量）方向的**方向导数（directional derivative）**是函数$f$ 在$u$ 方向的斜率。换句话说，方向导数是函数$f(\boldsymbol{x}+\alpha \boldsymbol{u})$关于$\alpha$ 的导数。使用链式法则，我们可以看到当$\alpha = 0$  时， $\frac{\partial}{\partial \alpha} f(\boldsymbol{x}+\alpha \boldsymbol{u})=\boldsymbol{u}^{\top} \nabla_{\boldsymbol{x}} f(\boldsymbol{x})$

为了最小化$f$，我们希望找到使$f$ 下降得最快的方向。计算方向导数：
$$
\min _{\boldsymbol{u}, \boldsymbol{u}^{\top}\boldsymbol{u}=1} \boldsymbol{u}^{\top} \nabla_{\boldsymbol{x}} f(\boldsymbol{x}) = \min _{\boldsymbol{u}, \boldsymbol{u}^{\top}\boldsymbol{u}=1}\|\boldsymbol{u}\|_{2}\left\|\nabla_{\boldsymbol{x}} f(\boldsymbol{x})\right\|_{2} \cos \theta
$$
其中 $\theta$ 是$u$ 与梯度的夹角。将$∥u∥_2 = 1$ 代入，并忽略与$u$ 无关的项，就能简化得到$\min _{u} \cos \theta$。这在$u$ 与梯度方向相反时取得最小。换句话说，梯度向量指向上坡，负梯度向量指向下坡。

我们在负梯度方向上移动可以减小$f$，这被称为**最速下降法(method of steepest descent)** 或**梯度下降（gradient descent）**。最速下降建议新的点为：
$$
\boldsymbol{x}^{\prime}=\boldsymbol{x}-\epsilon \nabla_{x} f(\boldsymbol{x})
$$
其中$\epsilon$ 为**学习率（learning rate）**，是一个确定步长大小的正标量。

仅使用梯度信息的优化算法被称为**一阶优化算法(first-order optimization algorithms)**，如梯度下降。使用Hessian 矩阵的优化算法被称为**二阶最优化算法(second-order optimization algorithms)**，如牛顿法（Newton’s method）。

牛顿法基于一个二阶泰勒展开来近似 $x^{(0)}$ 附近的 $f(x)$：
$$
f(\boldsymbol{x}) \approx f\left(\boldsymbol{x}^{(0)}\right)+\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)^{\top} \nabla_{\boldsymbol{x}} f\left(\boldsymbol{x}^{(0)}\right)+\frac{1}{2}\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)^{\top} \boldsymbol{H}(f)\left(\boldsymbol{x}^{(0)}\right)\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)
$$
通过计算，我们可以得到这个函数的临界点：
$$
\boldsymbol{x}^{*}=\boldsymbol{x}^{(0)}-\boldsymbol{H}(f)\left(\boldsymbol{x}^{(0)}\right)^{-1} \nabla_{\boldsymbol{x}} f\left(\boldsymbol{x}^{(0)}\right)
$$
在深度学习的背景下，限制函数需要满足**Lipschitz 连续（Lipschitz continuous）**。Lipschitz 连续函数的变化速度以**Lipschitz常数（Lipschitz constant）** $\mathcal{L}$ 为界：
$$
\forall \boldsymbol{x}, \forall \boldsymbol{y},|f(\boldsymbol{x})-f(\boldsymbol{y})| \leq \mathcal{L}\|\boldsymbol{x}-\boldsymbol{y}\|_{2}
$$


# 机器学习基础

## 基本概念

机器学习算法定义：对于某类任务$T$ 和性能度量 $P$，一个计算机程序被认为可以从经验$E$ 中学习是指，通过经验$E$ 改进后，它在任务$T$ 上由性能度量$P$ 衡量的性能有所提升。

- 任务$T$

  通常机器学习任务定义为机器学习系统应该如何处理**样本（example）**。样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的**特征（feature）**的集合。

- 性能度量$P$

  为了评估机器学习算法的能力，我们必须设计其性能的定量度量。常用的度量为**准确率（accuracy）**，指模型输出正确结果的样本比率

- 经验$E$

  机器学习算法可以大致分类为**无监督学习（unsupervised learning）**和**监督学习（supervised learning）**。

  - 无监督学习算法训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质
  - 监督学习算法训练含有很多特征的数据集，不过数据集中的样本都有一个**标签（label）**

  有些机器学习算法并不是训练于一个固定的数据集上。例如， **强化学习（reinforcement learning）**算法会和环境进行交互，所以学习系统和它的训练过程会有反馈回路。

## 容量、过拟合和欠拟合

### 一般性质

机器学习算法在未观测到的输入上表现良好的能力被称为**泛化（generalization）**，通常情况下，在训练集上计算一些被称为**训练误差（training error）**的度量误差，目标是降低训练误差。机器学习和优化不同的地方在于，我们也希望**泛化误差（generalization error）**（也被称为**测试误差（test error）**）很低。泛化误差被定义为新输入的误差期望。通常，我们度量模型在训练集中分出来的**测试集（test set）**样本上的性能，来评估机器学习模型的泛化误差。实现这一点的前提假设是训练集和测试集是**独立同分布（i.i.d.）**的。

机器学习的两个主要挑战： **欠拟合（underfitting）**和**过拟合（overfitting）**。欠拟合是指模型不能在训练集上获得足够低的误差。而过拟合是指训练误差和和测试误差之间的差距太大。通过调整模型的**容量（capacity）**，我们可以控制模型是否偏向于过拟合或者欠拟合。通俗来说，模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合，因为模型记住了不适用于测试集的训练集性质。

一种控制训练算法容量的方法是选择**假设空间（hypothesis space）**，即学习算法可以选择为解决方案的函数集。例如，线性回归算法将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数，这样做就增加了模型的容量。学习算法可以从哪些函数族中选择函数，这被称为模型的**表示容量（representational capacity）**

**奥卡姆剃刀（Occam’s razor）原则**：在同样能够解释已知观测现象的假设中，我们应该挑选‘‘最简单’’ 的那一个

**没有免费午餐定理（no free lunch theorem）**：没有一个机器学习算法在未事先观测的点上拥有比其他所有算法都更好的性能。这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法，我们必须在特定任务上设计性能良好的机器学习算法。

### 正则化

正则化一个学习函数 $f(x;\theta)$ 的模型，我们可以给代价函数添加被称为**正则化项（regularizer）**的惩罚项。这可以有助于改善高阶函数的过拟合问题。

以在线性回归训练中加入**权重衰减（weight decay）**为例，带权重衰减的线性回归最小化训练集上的均方误差和正则项的和$J(w)$，其偏好于平方$L^2 $范数较小的权重。具体如下：
$$
J(\boldsymbol{w})=\operatorname{MSE}_{\operatorname{train}}+\lambda \boldsymbol{w}^{\top} \boldsymbol{w}
$$
通过在最小化的目标中额外增加一项，我们明确地表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示对不同解的偏好，这些方法都被称为**正则化（regularization）**。

## 超参数

大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值通常为人为指定，而不是通过学习算法本身学习出来的。由于测试集不能参与到模型训练中，所以一般会从训练数据中构造**验证集（validation set）**，用于估计训练中或训练后的泛化误差，更新超参数。

## 估计、偏差和方差

### 点估计

点估计试图为一些感兴趣的量提供单个‘‘最优’’ 预测。感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数，也有可能是整个函数。为了区分参数估计和真实值，我们习惯将参数 $\theta$ 的点估计表示为 $\hat{\theta}$。令 ${x^{(1)},...,x^{(m)}}$ 是 $m$ 个独立同分布的数据点，**点估计（point estimator）**或**统计量（statistics）**是这些数据的任意函数：
$$
\hat{\theta}_m=g(x^{(1)},...x^{(m)})
$$
点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。我们假设有一个函数 $f(x)$ 表示 $y$ 和 $x$ 之间的近似关系。例如，我们可能假设 $y = f(x) + ϵ$，其中$ϵ$ 是 $y$ 中未能从 $x$ 预测的一部分。

### 偏差

估计的偏差定义为：

$$
bias(\hat{\theta}_m)=\mathbb{E}(\hat{\theta}_m)-\theta
$$
其中期望作用在所有数据（看作是从随机变量采样得到的）上，$\theta$ 是用于定义数据生成分布的 $\theta$ 的真实值。如果 $bias(\hat{\theta}_m)=0$，那么估计量 $\hat{\theta}_m$ 被称为是**无偏（unbiased）**，这意味着 $\mathbb{E}(\hat{\theta}_m)=\theta$。如果 $lim_{m\to\infty}bias(\hat{\theta}_m)=0$，那么估计量 $\hat{\theta}_m$ 被称为是**渐近无偏（asymptotically unbiased）**，这意味着$lim_{m\to\infty}\mathbb{E}(\hat{\theta}_m)=\theta$。

### 方差和标准差

我们有时会考虑估计量的另一个性质是它作为数据样本的函数，期望的变化程度是多少。估计量的方差（variance）为 $Var(\hat{\theta})$ 其中随机变量是训练集。方差的平方根被称为标准差（standard error），记作 $SE(\hat{\theta})$。

均值的标准差被记作：
$$
SE(\hat{\mu}_{m})=\sqrt{Var[\frac{1}{m}\sum_{i=1}^{m}x^{(i)}]}=\frac{\sigma}{\sqrt{m}}
$$
其中 $\sigma$ 是样本 $x^{(i)}$ 的真实标准差。

### 权衡偏差和方差以最小化均方误差

偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函数或参数的误差期望。而方差度量着数据上任意特定采样可能导致的估计期望的偏差。

判断这种权衡最常用的方法是交叉验证。此外，也可以比较这些估计的**均方误差（mean squared error, MSE）**：
$$
MSE=\mathbb{E}[(\hat{\theta}_m-\theta)^2]=Bias(\hat{\theta}_m)^2+Var(\hat{\theta}_m)
$$
MSE度量着估计和真实参数 $\theta$ 之间平方误差的总体期望偏差，理想的估计具有较小的MSE或是在检查中会稍微约
束它们的偏差和方差。

### 一致性

我们希望当数据集中数据点的数量 $m$ 增加时，点估计会收敛到对应参数的真实值，称为**一致性（consistency）**
$$
plim_{m\to\infty}\hat{\theta}_m=0
$$
符号 $plim$ 表示依概率收敛，即对于任意的 $ϵ > 0$，当 $m \to \infty$ 时，有 $P(|\hat{\theta}_m-\theta|>\epsilon)\to0$

一致性保证了估计量的偏差会随数据样本数目的增多而减少

## 最大似然估计

考虑一组含有m 个样本的数据集 $X = \{x^{(1)},...,x^{(m)}\}$，独立地由未知的真实数据生成分布 $p_{data}(x)$ 生成。令 $p_{model}(x;\theta)$ 是一族由 $\theta$ 确定在相同空间上的概率分布。换言之，$p_{model}(x;\theta)$ 将任意输入 $x$ 映射到实数来估计真实概率 $p_{data}(x)$。对 $\theta$ 的最大似然估计被定义为：
$$
\theta_{ML}=argmax_\theta p_{model}(\mathbb{x};\theta)\\
=argmax_\theta \prod_{i=1}^{m} p_{model}(x^{(i)};\theta)
$$
多个概率的乘积会因很多原因不便于计算。例如，计算中很可能会出现数值下溢。为了得到一个便于计算的等价优化问题，我们观察到似然对数不会改变其 $argmax$ 但是将乘积转化成了便于计算的求和形式：
$$
\theta_{ML}=argmax_\theta \sum_{i=1}^{m}logp_{model}(x^{(i)};\theta)
$$
注：跟 $max$ 函数不同，$argmax(f(x))$ 函数是使得 $f(x)$ 取得最大值所对应的变量点 $x$ (或 $x$ 的集合)
$$
max_{x}f(x)=\{f(x)|\forall y:f(y)\le f(x)\}\\
argmax_{x}f(x)=\{x|\forall y:f(y)\le f(x)\}
$$
因此当我们重新缩放代价函数时 $arg max$ 不会改变，我们可以除以 $m$ 得到和训练数据经验分布 $\hat{p}_{data}$ 相关的期望作为准则：
$$
\theta_{ML}=argmax_\theta \mathbb{E}_{x \sim \hat{p}_{data}}logp_{model}(x;\theta)
$$
最大似然估计很容易扩展到估计条件概率 $P(y|x;\theta)$，从而给定 $x$ 预测 $y$。构成了大多数监督学习的基础，如果 $X$ 表示所有的输入，$Y$ 表示我们观测到的目标，那么条件最大似然估计是:
$$
\theta_{ML}=argmax_\theta P(Y|X;\theta)
$$
如果假设样本是独立同分布的，那么这可以分解成：
$$
\theta_{ML}=argmax_\theta \sum_{i=1}^{m}P(y^{(i)}|x^{(i)};\theta)
$$
在合适的条件下，最大似然估计具有一致性，意味着训练样本数目趋向于无穷大时，参数的最大似然估计会收敛到参数的真实值，而且具有良好的 **统计效率（statistic efficiency）**，因此最大似然通常是机器学习中的首选估计。

## 监督学习算法

粗略地说，监督学习算法是给定一组输入 $x$ 和输出 $y$ 的训练集，学习如何关联输入和输出。

**逻辑回归（logistic regression）**：
$$
P(y=1|x;\theta)=\sigma(\theta^{\top}x)
$$
**支持向量机（support vector machine, SVM）**是监督学习中最有影响力的方法之一，不同于逻辑回归的是，支持向量机不输出概率，只输出类别。当 $w^{\top}x + b$ 为正时，支持向量机预测属于正类。当 $w^{\top}x + b$ 为负时，支持向量机预测属于负类。

支持向量机的一个重要创新是**核技巧（kernel trick）**。核技巧观察到许多机器学习算法都可以写成样本间点积的形式。例如，支持向量机中的线性函数可以重写为：
$$
w^{\top}x + b=b+\sum_{i=1}^{m}\alpha_ix^{\top}x^{(i)}
$$
其中，$x(i)$ 是训练样本，$\alpha$ 是系数向量。学习算法重写为这种形式允许我们将 $x$ 替换为高维空间特征函数 $ϕ(x)$ 的输出，点积替换为被称为**核函数（kernel function）**的函数 $k(x,x^{(i)}) = ϕ(x) \cdot ϕ(x^{(i)})$。使用核估计替换点积之后，我们可以使用如下函数进行预测：
$$
f(x)=b+\sum_{i}\alpha_ik(x,x^{(i)})
$$
这个函数关于 $x$ 是非线性的，关于 $ϕ(x)$ 是线性的，最常用的核函数是**高斯核（Gaussian kernel）**：
$$
k(u,v)=\mathcal{N}(u-v;0;\sigma^2I)
$$
其中 $\mathcal{N}(x;\mu;\sum)$ 是标准正态密度。这个核也被称为**径向基函数（radial basis function, RBF）核**，因为其值沿 $v$ 中从 $u$ 向外辐射的方向减小。使用核技巧的算法类别被称为**核机器（kernel machine）**或**核方法（kernel method）**

## 无监督学习算法

无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。

### 主成分分析

PCA算法提供了一种压缩数据的方式，也可以将PCA视为学习数据表示的无监督学习算法。PCA学习一种比原始输入维数更低的表示，它也学习了一种元素之间彼此没有线性相关的表示。这是学习表示中元素统计独立标准的第一步。要实现完全独立性，表示学习算法也必须去掉变量间的非线性关系。PCA这种将数据变换为元素之间彼此不相关表示的能力是PCA的一个重要性质。它是消除数据中未知变化因素的简单表示示例。

## 随机梯度下降

几乎所有的深度学习算法都用到了一个非常重要的算法： **随机梯度下降（stochastic gradient descent, SGD）**。随机梯度下降是梯度下降算法的一个扩展。机器学习中好的泛化需要大的训练集，但大的训练集的计算代价也更大。机器学习算法中的代价函数通常可以分解成每个样本的代价函数的总和，随着训练集规模增长为数十亿的样本，计算一步梯度
也会消耗相当长的时间。

随机梯度下降的核心是，梯度是期望，期望可使用小规模的样本近似估计。具体而言，在算法的每一步，我们从训练集中均匀抽出**小批量（minibatch）样本**，$\mathbb{B} = \{x_1,x_2,...,x_{m'}\}$。小批量的数目 $m′$ 通常是一个相对较小的数，从一到几百，当训练集大小 $m$ 增长时，$m′$ 通常是固定的。我们可能在拟合几十亿的样本时，每次更新计算只用到几百个样本。梯度的估计可以表示成：
$$
g=\frac{1}{m'}\nabla_{\theta}\sum_{i=1}^{m'}L(x^{(i)},y^{(i)},\theta)
$$
使用来自小批量 $\mathbb{B}$ 的样本。然后，随机梯度下降算法使用如下的梯度下降估计：
$$
\theta \gets \theta-\epsilon g
$$
可以认为用SGD训练模型的渐近代价是关于 $m$ 的函数的 $O(1)$ 级别。

# 深度前馈网络

**深度前馈网络（deep feedforward network）**，也叫作**前馈神经网络（feedforward neural network）**或者**多层感知机（multilayer perceptron, MLP）**，是典型的深度学习模型。前馈网络的目标是近似某个函数，前馈网络定义了一个映射 $y = f(x; \theta)$，并且学习参数 $\theta$ 的值，使它能够得到最佳的函数近似。这种模型被称为**前向（feedforward）**的，是因为信息流过 $x$ 的函数，流经用于定义 $f$ 的中间计算过程，最终到达输出 $y$。在模型的输出和模型本身之间没有**反馈**
**（feedback）连接**。